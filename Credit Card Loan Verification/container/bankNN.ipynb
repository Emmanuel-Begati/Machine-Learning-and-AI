{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7373c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing my libraries \n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "from collections import Counter\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b005d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bankloan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdde214",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b51cdd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a20d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LoanAmount'].isna().sum()# because i noticed there was NaN in the LoanAmount column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b65b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf92f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b5455b",
   "metadata": {},
   "source": [
    "since we have 614 rows.. then removing just a couple 50 rows should be okay.. because we want to get clean data right??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaa7cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4452e230",
   "metadata": {},
   "source": [
    "We have successfully cleared all our NaN values\n",
    "Let's check our shape now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5600c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b36eda",
   "metadata": {},
   "source": [
    "We dropped a number of rows.. but that should not harm our models as much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b42ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a4c8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Loan_ID', axis=1) #We dont need IDs when building our models\n",
    "df['LoanAmount']=(df['LoanAmount']*1000).astype(int)\n",
    "Counter(df['Loan_Status']) #We want to know if our dataset is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e3024",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_y=df['Loan_Status']\n",
    "pre_X=df.drop('Loan_Status', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcaf8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c589fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_X = pd.get_dummies(pre_X).astype(int) #We are using OneHotEncoding to work on the data so that the computer knows that it will work with numbers and not strings\n",
    "dm_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1065a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_y = pre_y.map(dict(Y=1, N=0))#we are not using get dummies here because we want the values to be on one column\n",
    "dm_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8278c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='minority')#we are using SMOTE as our sampling method to make the stuff balanced\n",
    "X1, y = smote.fit_resample(dm_X, dm_y)\n",
    "sc = MinMaxScaler()\n",
    "X = sc.fit_transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b65176",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c5aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8046644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "classifier.add(Dense(200, activation='relu', kernel_initializer='random_normal', input_dim=X_test.shape[1]))\n",
    "classifier.add(Dense(400, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dense(4, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(X_train, y_train, batch_size=20, epochs=100, verbose=0)\n",
    "eval_model = classifier.evaluate(X_train, y_train)\n",
    "eval_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee61506",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d0d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746d6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap='Reds', cbar=True); #annot=True to annotate cells\n",
    "\n",
    "#labels, title and ticks\n",
    "ax.set_xlabel('Predicted');\n",
    "ax.set_ylabel('Actual');\n",
    "ax.set_title('Confusion Matrix');\n",
    "ax.xaxis.set_ticklabels(['No', 'Yes']); \n",
    "ax.yaxis.set_ticklabels(['No', 'Yes']); \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c80baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm #for some reason the other numbers are not showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47a0555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "filename = 'loan_model.pkl'\n",
    "joblib.dump(classifier, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9715641",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(X_test, columns=dm_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ace68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a99ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_excel('test.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df504983",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scalers.pkl', 'rb') as f:\n",
    "    scaler = joblib.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122c23e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
